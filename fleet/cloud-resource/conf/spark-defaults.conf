#spark
spark.master                           local
spark.sql.warehouse.dir                s3a://david-test1/warehouse
spark.dynamicAllocation.enabled        false
#hive
#hive.exec.scratchdir                   s3a://david-test1/hive/scratchdir
#hive.metastore.uris                    thrift://10.61.118.87:9083
leo.metastore.endpoint                 http://100.94.21.238:8080
leo.query.result.bucket.prefix         leo-query-data-user2-
#obs
spark.hadoop.fs.s3a.impl               org.apache.hadoop.fs.obs.OBSFileSystem
fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.obs.OBS
spark.hadoop.fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.obs.OBS
fs.AbstractFileSystem.obs.impl=org.apache.hadoop.fs.obs.OBS
spark.hadoop.fs.AbstractFileSystem.obs.impl=org.apache.hadoop.fs.obs.OBS

spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory
spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3n org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory
spark.hadoop.mapreduce.outputcommitter.factory.scheme.obs org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory
#dis
carbon.source.endpoint                 https://dis.cn-north-7.myhuaweicloud.com
carbon.source.region                   cn-north-7
carbon.source.projectid                ce6926fe7ef8427492a0fb93fad3edca
#hbase
leo.hbase.to.carbon.enable             false

#spring
leo.leader.endpoint.port               8080
spark.pythonUDF.ignoreIfPythonNotFound true